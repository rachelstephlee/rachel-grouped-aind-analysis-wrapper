{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09091844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from aind_dynamic_foraging_basic_analysis.plot import plot_fip as pf\n",
    "from aind_dynamic_foraging_basic_analysis.plot import plot_foraging_session as pb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e818497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59c68f",
   "metadata": {},
   "source": [
    "# get the data, get the analysis specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81d8b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 input job models to run analysis on.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "DATA_PATH: Path = Path(\"/data\")  # TODO: don't hardcode\n",
    "ANALYSIS_BUCKET = os.getenv(\"ANALYSIS_BUCKET\")\n",
    "\n",
    "\n",
    "input_model_paths = tuple(DATA_PATH.glob('job_dict/*'))\n",
    "print(f\"Found {len(input_model_paths)} input job models to run analysis on.\")\n",
    "analysis_specs = None\n",
    "\n",
    "analysis_spec_path = tuple(DATA_PATH.glob(\"analysis_parameters.json\"))\n",
    "if analysis_spec_path:\n",
    "    with open(analysis_spec_path[0], \"r\") as f:\n",
    "        analysis_specs = json.load(f)\n",
    "\n",
    "from analysis_pipeline_utils.analysis_dispatch_model import AnalysisDispatchModel\n",
    "import utils as utils\n",
    "from analysis_model import (\n",
    "    SummaryPlotsAnalysisSpecification, SummaryPlotsAnalysisSpecificationCLI\n",
    ")\n",
    "for model_path in input_model_paths:\n",
    "    with open(model_path, \"r\") as f:\n",
    "        analysis_dispatch_inputs = AnalysisDispatchModel.model_validate(json.load(f))\n",
    "    \n",
    "    analysis_specification = SummaryPlotsAnalysisSpecification.model_validate(analysis_specs).model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1768c",
   "metadata": {},
   "source": [
    "# get the data and set them up right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce8c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rachel_analysis_framework_utils as r_utils\n",
    "import analysis_util\n",
    "from plots import summary_plots\n",
    "from aind_dynamic_foraging_basic_analysis.metrics import trial_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765efb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving channels: ['R_0', 'G_0', 'G_1']\n",
      "CURRENTLY RUNNING 1/2: 726649_2024-09-12\n",
      "--------------------------------------------------\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "CURRENTLY RUNNING 2/2: 726649_2024-09-16\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/nwb_utils.py:483: UserWarning: Response time greater than minimum, something unusual happened\n",
      "  warnings.warn(\"Response time greater than minimum, something unusual happened\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Retrieving foraging model QLearning_L1F1_CK1_softmax\n",
      "Query: {'analysis_spec.analysis_name': 'MLE fitting', 'analysis_spec.analysis_ver': 'first version @ 0.10.0', 'subject_id': '726649', 'session_date': '2024-09-12', 'analysis_results.fit_settings.agent_alias': 'QLearning_L1F1_CK1_softmax'}\n",
      "Found 1 MLE fitting records!\n",
      "Found 1 successful MLE fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get latent variables from s3: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: {'analysis_spec.analysis_name': 'MLE fitting', 'analysis_spec.analysis_ver': 'first version @ 0.10.0', 'subject_id': '726649', 'session_date': '2024-09-16', 'analysis_results.fit_settings.agent_alias': 'QLearning_L1F1_CK1_softmax'}\n",
      "Found 1 MLE fitting records!\n",
      "Found 1 successful MLE fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get latent variables from s3: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:378: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_chosen\"] = chosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_unchosen\"] = unchosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:380: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_sum\"] = df_ses[\"Q_left\"].values + df_ses[\"Q_right\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_Delta\"] = df_ses[\"Q_chosen\"].values - df_ses[\"Q_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_change\"] = np.concatenate([[0], np.diff(chosen_values)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:384: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_chosen\"] = chosen_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:385: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_unchosen\"] = unchosen_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:386: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_sum\"] = df_ses[\"L_prob\"].values + df_ses[\"R_prob\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_Delta\"] = df_ses[\"P_chosen\"].values - df_ses[\"P_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_change\"] = np.concatenate([[0], np.diff(chosen_probabilities)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_chosen\"] = chosen_kernels\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_unchosen\"] = unchosen_kernels\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:393: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_sum\"] = df_ses[\"L_kernel\"].values + df_ses[\"R_kernel\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_Delta\"] = df_ses[\"K_chosen\"].values - df_ses[\"K_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_change\"] = np.concatenate([[0], np.diff(chosen_kernels)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Cprobstay\"] = chosen_stay_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:398: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"RPE_earned\"] = df_ses[\"earned_reward\"].astype(float) - chosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:399: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"RPE_all\"] = (\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:378: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_chosen\"] = chosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_unchosen\"] = unchosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:380: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_sum\"] = df_ses[\"Q_left\"].values + df_ses[\"Q_right\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_Delta\"] = df_ses[\"Q_chosen\"].values - df_ses[\"Q_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Q_change\"] = np.concatenate([[0], np.diff(chosen_values)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:384: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_chosen\"] = chosen_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:385: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_unchosen\"] = unchosen_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:386: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_sum\"] = df_ses[\"L_prob\"].values + df_ses[\"R_prob\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_Delta\"] = df_ses[\"P_chosen\"].values - df_ses[\"P_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"P_change\"] = np.concatenate([[0], np.diff(chosen_probabilities)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_chosen\"] = chosen_kernels\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_unchosen\"] = unchosen_kernels\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:393: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_sum\"] = df_ses[\"L_kernel\"].values + df_ses[\"R_kernel\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_Delta\"] = df_ses[\"K_chosen\"].values - df_ses[\"K_unchosen\"].values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"K_change\"] = np.concatenate([[0], np.diff(chosen_kernels)])\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"Cprobstay\"] = chosen_stay_probabilities\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:398: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"RPE_earned\"] = df_ses[\"earned_reward\"].astype(float) - chosen_values\n",
      "/src/aind-dynamic-foraging-data-utils/src/aind_dynamic_foraging_data_utils/enrich_dfs.py:399: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ses.loc[:, \"RPE_all\"] = (\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parameters = analysis_specification\n",
    "\n",
    "(df_sess, df_trials, df_events, df_fip) = r_utils.get_nwb_processed(analysis_dispatch_inputs.file_location, **parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5bb57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor this out to r_utils. \n",
    "\n",
    "\n",
    "df_trials['reward_all'] = df_trials['earned_reward'] + df_trials['extra_reward']\n",
    "# Compute num_reward_past and num_no_reward_past\n",
    "df_trials['reward_shifted'] = df_trials.groupby('ses_idx')['reward_all'].shift(1)  # Shift to look at past values\n",
    "\n",
    "df_trials['num_reward_past'] = df_trials.groupby(\n",
    "                        (df_trials['reward_shifted'] != df_trials['reward_all']).cumsum()).cumcount() + 1\n",
    "\n",
    "# Set 'NA' for mismatched reward types\n",
    "df_trials.loc[df_trials['reward_all'] == 0, 'num_reward_past'] = df_trials.loc[df_trials['reward_all'] == 0, 'num_reward_past']* -1 \n",
    "\n",
    "# Drop the temporary column\n",
    "df_trials.drop(columns=['reward_shifted'], inplace=True)\n",
    "\n",
    "\n",
    "RPE_binned3_label_names = [str(np.round(i,2)) for i in np.arange(-1,0.99,1/3)]\n",
    "\n",
    "bins = np.arange(-1,1.01,1/3)\n",
    "bins[-1] = 1.001\n",
    "\n",
    "df_trials['RPE-binned3'] = pd.cut(df_trials['RPE_earned'],# all versus earned not a huge difference\n",
    "                    bins = bins, right = True, labels=RPE_binned3_label_names)\n",
    "\n",
    "(df_sess, nwbs_by_week) = analysis_util.get_dummy_nwbs_by_week(df_sess, df_trials, df_events, df_fip) \n",
    "\n",
    "\n",
    "# TODO: will need to refactor code so there's flexibility on the plots that come out\n",
    "#       consult alex? or figure it out on my own. \n",
    "# get average activity \n",
    "data_column = 'data_z_norm'\n",
    "alignment_event='choice_time_in_session'\n",
    "rpe_slope_dict = {}\n",
    "for channel in list(analysis_specification[\"channels\"].keys()):\n",
    "    avg_signal_col = summary_plots.output_col_name(channel, data_column, alignment_event)\n",
    "    for nwb_week in nwbs_by_week:\n",
    "    \n",
    "        nwb_week = trial_metrics.get_average_signal_window_multi(\n",
    "                        nwb_week,\n",
    "                        alignment_event='choice_time_in_session',\n",
    "                        offsets=[0.33, 1],\n",
    "                        channel=channel,\n",
    "                        data_column=data_column,\n",
    "                        output_col = avg_signal_col\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59e1ec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'animal_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'animal_response'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_foraging_session_nwb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnwbs_by_week\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/src/aind-dynamic-foraging-basic-analysis/src/aind_dynamic_foraging_basic_analysis/plot/plot_foraging_session.py:47\u001b[0m, in \u001b[0;36mplot_foraging_session_nwb\u001b[0;34m(nwb, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_list\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     45\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_list\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     46\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m plot_foraging_session(\n\u001b[0;32m---> 47\u001b[0m         [np\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_trials\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manimal_response\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues],\n\u001b[1;32m     48\u001b[0m         nwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearned_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     49\u001b[0m         [nwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_probabilityL\u001b[39m\u001b[38;5;124m\"\u001b[39m], nwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_probabilityR\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     50\u001b[0m         bias\u001b[38;5;241m=\u001b[39mnwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     51\u001b[0m         bias_lower\u001b[38;5;241m=\u001b[39m[x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside_bias_confidence_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues],\n\u001b[1;32m     52\u001b[0m         bias_upper\u001b[38;5;241m=\u001b[39m[x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nwb\u001b[38;5;241m.\u001b[39mdf_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside_bias_confidence_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues],\n\u001b[1;32m     53\u001b[0m         autowater_offered\u001b[38;5;241m=\u001b[39mnwb\u001b[38;5;241m.\u001b[39mdf_trials[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_waterL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_waterR\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Add some text info\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# TODO, waiting for AIND metadata to get integrated before adding this info:\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# {df_session.metadata.rig.iloc[0]}, {df_session.metadata.user_name.iloc[0]}\\n'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# f'ignored {df_session.session_stats.autowater_ignored.iloc[0]}\\n'\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# f'FORAGING finished rate {df_session.session_stats.finished_rate.iloc[0]:.2%}, '\u001b[39;00m\n\u001b[1;32m     65\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m1.05\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     transform\u001b[38;5;241m=\u001b[39maxes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtransAxes,\n\u001b[1;32m     74\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'animal_response'"
     ]
    }
   ],
   "source": [
    "\n",
    "pb.plot_foraging_session_nwb(nwbs_by_week[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cc15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rewarded_historyL</th>\n",
       "      <th>rewarded_historyR</th>\n",
       "      <th>side_bias</th>\n",
       "      <th>side_bias_confidence_interval</th>\n",
       "      <th>bait_left</th>\n",
       "      <th>bait_right</th>\n",
       "      <th>base_reward_probability_sum</th>\n",
       "      <th>reward_probabilityL</th>\n",
       "      <th>...</th>\n",
       "      <th>data_z_G_1_baseline</th>\n",
       "      <th>data_R_0_baseline</th>\n",
       "      <th>data_z_R_0_baseline</th>\n",
       "      <th>reward_all</th>\n",
       "      <th>num_reward_past</th>\n",
       "      <th>RPE-binned3</th>\n",
       "      <th>week_interval</th>\n",
       "      <th>avg_data_z_norm_R_0_choice_time</th>\n",
       "      <th>avg_data_z_norm_G_0_choice_time</th>\n",
       "      <th>avg_data_z_norm_G_1_choice_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253120</td>\n",
       "      <td>2485.121382</td>\n",
       "      <td>0.714040</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078969</td>\n",
       "      <td>1.050893</td>\n",
       "      <td>1.122472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.834826</td>\n",
       "      <td>2428.392225</td>\n",
       "      <td>0.596711</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.150323</td>\n",
       "      <td>3.940241</td>\n",
       "      <td>4.558299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712887</td>\n",
       "      <td>3389.024622</td>\n",
       "      <td>2.583516</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350892</td>\n",
       "      <td>1.052745</td>\n",
       "      <td>1.570548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205047</td>\n",
       "      <td>3328.141685</td>\n",
       "      <td>2.457596</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756732</td>\n",
       "      <td>2.356876</td>\n",
       "      <td>1.727903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635668</td>\n",
       "      <td>3169.831533</td>\n",
       "      <td>2.130175</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570183</td>\n",
       "      <td>2.047199</td>\n",
       "      <td>2.226870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.325052</td>\n",
       "      <td>1585.814255</td>\n",
       "      <td>-1.145931</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.155704</td>\n",
       "      <td>0.609415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.360709</td>\n",
       "      <td>1543.471274</td>\n",
       "      <td>-1.233506</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.063956</td>\n",
       "      <td>0.284147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.879338</td>\n",
       "      <td>1636.039741</td>\n",
       "      <td>-1.042053</td>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.077024</td>\n",
       "      <td>-0.618143</td>\n",
       "      <td>0.101645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.634625</td>\n",
       "      <td>1652.575378</td>\n",
       "      <td>-1.007854</td>\n",
       "      <td>False</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.056925</td>\n",
       "      <td>-0.727662</td>\n",
       "      <td>0.025982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320808</td>\n",
       "      <td>1765.536069</td>\n",
       "      <td>-0.774226</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.068524</td>\n",
       "      <td>-1.334157</td>\n",
       "      <td>-0.088609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trial  choice  rewarded_historyL  rewarded_historyR  side_bias  \\\n",
       "0        0     0.0               True              False        NaN   \n",
       "1        1     0.0               True              False        NaN   \n",
       "2        2     0.0               True              False        NaN   \n",
       "3        3     0.0               True              False        NaN   \n",
       "4        4     0.0               True              False        NaN   \n",
       "..     ...     ...                ...                ...        ...   \n",
       "192    276     1.0              False               True        NaN   \n",
       "193    285     1.0              False               True        NaN   \n",
       "194    287     1.0              False              False        NaN   \n",
       "195    296     1.0              False              False        NaN   \n",
       "196    308     0.0               True              False        NaN   \n",
       "\n",
       "    side_bias_confidence_interval  bait_left  bait_right  \\\n",
       "0                      [nan, nan]       True        True   \n",
       "1                      [nan, nan]       True        True   \n",
       "2                      [nan, nan]       True        True   \n",
       "3                      [nan, nan]       True        True   \n",
       "4                      [nan, nan]       True        True   \n",
       "..                            ...        ...         ...   \n",
       "192                    [nan, nan]      False        True   \n",
       "193                    [nan, nan]      False        True   \n",
       "194                    [nan, nan]       True       False   \n",
       "195                    [nan, nan]       True       False   \n",
       "196                    [nan, nan]       True       False   \n",
       "\n",
       "     base_reward_probability_sum  reward_probabilityL  ...  \\\n",
       "0                            0.8                  0.7  ...   \n",
       "1                            0.8                  0.7  ...   \n",
       "2                            0.8                  0.7  ...   \n",
       "3                            0.8                  0.7  ...   \n",
       "4                            0.8                  0.7  ...   \n",
       "..                           ...                  ...  ...   \n",
       "192                          0.8                  0.1  ...   \n",
       "193                          0.8                  0.1  ...   \n",
       "194                          0.8                  0.7  ...   \n",
       "195                          0.8                  0.7  ...   \n",
       "196                          0.8                  0.7  ...   \n",
       "\n",
       "     data_z_G_1_baseline  data_R_0_baseline  data_z_R_0_baseline  reward_all  \\\n",
       "0              -0.253120        2485.121382             0.714040        True   \n",
       "1              -0.834826        2428.392225             0.596711        True   \n",
       "2               1.712887        3389.024622             2.583516        True   \n",
       "3               1.205047        3328.141685             2.457596        True   \n",
       "4               0.635668        3169.831533             2.130175        True   \n",
       "..                   ...                ...                  ...         ...   \n",
       "192            -1.325052        1585.814255            -1.145931        True   \n",
       "193            -1.360709        1543.471274            -1.233506        True   \n",
       "194            -1.879338        1636.039741            -1.042053       False   \n",
       "195            -1.634625        1652.575378            -1.007854       False   \n",
       "196            -0.320808        1765.536069            -0.774226        True   \n",
       "\n",
       "     num_reward_past  RPE-binned3  week_interval  \\\n",
       "0                  1         0.67              1   \n",
       "1                  2         0.33              1   \n",
       "2                  3         -0.0              1   \n",
       "3                  4         -0.0              1   \n",
       "4                  5         -0.0              1   \n",
       "..               ...          ...            ...   \n",
       "192                1         0.67              1   \n",
       "193                1         0.33              1   \n",
       "194               -2         -1.0              1   \n",
       "195              -11        -0.67              1   \n",
       "196                1         0.67              1   \n",
       "\n",
       "     avg_data_z_norm_R_0_choice_time  avg_data_z_norm_G_0_choice_time  \\\n",
       "0                           0.078969                         1.050893   \n",
       "1                           1.150323                         3.940241   \n",
       "2                           0.350892                         1.052745   \n",
       "3                           0.756732                         2.356876   \n",
       "4                           0.570183                         2.047199   \n",
       "..                               ...                              ...   \n",
       "192                         0.014622                         0.155704   \n",
       "193                         0.053791                         0.063956   \n",
       "194                        -0.077024                        -0.618143   \n",
       "195                        -0.056925                        -0.727662   \n",
       "196                        -0.068524                        -1.334157   \n",
       "\n",
       "     avg_data_z_norm_G_1_choice_time  \n",
       "0                           1.122472  \n",
       "1                           4.558299  \n",
       "2                           1.570548  \n",
       "3                           1.727903  \n",
       "4                           2.226870  \n",
       "..                               ...  \n",
       "192                         0.609415  \n",
       "193                         0.284147  \n",
       "194                         0.101645  \n",
       "195                         0.025982  \n",
       "196                        -0.088609  \n",
       "\n",
       "[197 rows x 104 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwbs_by_week[0][0].df_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac6964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
